{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1782fe40-41ed-4d3b-abb7-fbe7e32fd241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1429b77d-09a8-4e31-8b00-3f7c6b8eb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "ven_info = pd.read_csv(\"image_data/venomous_status_metadata.csv\", names=[\"nid\", \"class_id\", \"ven\"], header=0)\n",
    "train_info = pd.read_csv(\"image_data/train_images_metadata.csv\", index_col=0)\n",
    "relevant = train_info[[\"image_path\", \"class_id\",]].merge(ven_info, on=\"class_id\")\n",
    "n_classes = len(ven_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1fd095c-faa7-4bb5-a8fd-edbffd152b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "def load_and_preprocess1(img_path, y1, img_size=(240, 240), onehot=True):\n",
    "    img = tf.io.read_file(\"image_data/train_images_small/\" + img_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, img_size)\n",
    "    #img = tf.cast(img, tf.float32) / 255.0\n",
    "    if onehot: y1 = tf.one_hot(y1, depth=n_classes)\n",
    "    return img, y1\n",
    "\n",
    "def make_dataset1(df, what):\n",
    "    slices = (df['image_path'].values, df[what].values)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)\n",
    "    lp = load_and_preprocess1\n",
    "    if what==\"ven\": lp = lambda x, y: load_and_preprocess1(x, y, onehot=False)\n",
    "    ds = ds.map(lp, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ee02ede-97a7-49ad-86af-abeb7db3e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, test_val_paths = train_test_split(relevant, test_size=0.3, random_state=42) # does shuffle\n",
    "val_paths, test_paths = train_test_split(test_val_paths, test_size=0.33, random_state=42) # does shuffle\n",
    "cid_train_ds = make_dataset1(train_paths, \"nid\")\n",
    "cid_val_ds = make_dataset1(val_paths, \"nid\")\n",
    "cid_test_ds = make_dataset1(test_paths, \"nid\")\n",
    "ven_train_ds = make_dataset1(train_paths, \"ven\")\n",
    "ven_val_ds = make_dataset1(val_paths, \"ven\")\n",
    "ven_test_ds = make_dataset1(test_paths, \"ven\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62aa0ca2-eae6-4a47-abaf-8814a6440a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_training_graphs():\n",
    "    plt.plot(history.history['class_id_accuracy'])\n",
    "    plt.plot(history.history['val_class_id_accuracy'])\n",
    "    plt.plot(history.history['ven_accuracy'])\n",
    "    plt.plot(history.history['val_ven_accuracy'])\n",
    "    plt.title('model acc')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['class_id_acc', 'val_class_id_acc', 'ven_acc', 'val_ven_acc'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad0bcc1-1459-4528-80bb-b9079e9c188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, Conv2D, Dense, Input, MaxPooling2D, Dropout, Concatenate\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1036fe86-9bd3-445e-a5d6-e3cc42f4897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedBinaryCrossentropy(losses.BinaryCrossentropy):\n",
    "    def call(self, y_true, y_pred):\n",
    "        l = super().call(y_true, y_pred)\n",
    "        weights = y_true * 0.8 + (1 - y_true) * 0.2\n",
    "        return tf.reduce_mean(l * weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ffa1eea-ef2e-48d6-96a7-4eaa784fc758",
   "metadata": {},
   "outputs": [],
   "source": [
    "## separate \n",
    "\n",
    "inp1 = Input(shape=(240, 240, 3))\n",
    "# Conv A\n",
    "x1 = Conv2D(16, (5, 5), padding=\"valid\")(inp1)\n",
    "x1 = MaxPooling2D(pool_size=(5,5))(x1)\n",
    "x1 = Conv2D(64, (3, 3), padding=\"valid\")(x1)\n",
    "x1 = MaxPooling2D(pool_size=(3,3))(x1)\n",
    "x1 = Conv2D(32, (3, 3), padding=\"valid\")(x1)\n",
    "x1 = MaxPooling2D()(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "x1 = Dense(32, activation=\"relu\")(x1)\n",
    "x1 = Dense(32, activation=\"relu\")(x1)\n",
    "ven_output = Dense(1, activation=\"sigmoid\", name='ven')(x1)\n",
    "\n",
    "\n",
    "inp2 = Input(shape=(240, 240, 3))\n",
    "# Conv B\n",
    "x2 = Conv2D(16, (5, 5), padding=\"valid\")(inp2)\n",
    "x2 = MaxPooling2D(pool_size=(5,5))(x2)\n",
    "x2 = Conv2D(64, (3, 3), padding=\"valid\")(x2)\n",
    "x2 = MaxPooling2D(pool_size=(3,3))(x2)\n",
    "x2 = Conv2D(32, (3, 3), padding=\"valid\")(x2)\n",
    "x2 = MaxPooling2D()(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "x2 = Dense(32, activation=\"relu\")(x2)\n",
    "x2 = Dense(32, activation=\"relu\")(x2)\n",
    "class_output = Dense(n_classes, activation=\"sigmoid\", name='class_id')(x2)\n",
    "\n",
    "ven_model = Model(inputs=inp1, outputs=ven_output, name='ven_model')\n",
    "cid_model = Model(inputs=inp2, outputs=class_output, name='cid_model')\n",
    "\n",
    "ven_model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(),\n",
    "    loss=WeightedBinaryCrossentropy(),\n",
    "    metrics=['accuracy'])\n",
    "cid_model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(),\n",
    "    loss=losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0031e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import ConvNeXtTiny\n",
    "\n",
    "# 1. Load the model without the classification head (include_top=False)\n",
    "base_model = ConvNeXtTiny(\n",
    "    weights='imagenet',\n",
    "    include_top=False,  # This is crucial for feature extraction\n",
    "    input_shape=(240, 240, 3) # Specify input size\n",
    ")\n",
    "\n",
    "# 2. Freeze the weights of the base model\n",
    "# This prevents the pre-trained weights from being updated during training.\n",
    "base_model.trainable = False\n",
    "\n",
    "# 3. Build your new custom classification head\n",
    "inputs = tf.keras.Input(shape=(240, 240, 3))\n",
    "x = base_model(inputs, training=False) # Pass the inputs through the frozen base\n",
    "x = layers.GlobalAveragePooling2D()(x) # Apply pooling\n",
    "x1 = Dense(64, activation=\"relu\")(x)\n",
    "x1 = Dense(32, activation=\"relu\")(x1)\n",
    "class_output = Dense(n_classes, activation=\"softmax\", name='class_id')(x1)\n",
    "\n",
    "cid_model = Model(inputs=inputs, outputs=class_output, name='cid_model')\n",
    "\n",
    "cid_model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(),\n",
    "    loss=losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b77bb59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# 1. Load the model without the classification head (include_top=False)\n",
    "base_model = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,  # This is crucial for feature extraction\n",
    "    input_shape=(240, 240, 3) # Specify input size\n",
    ")\n",
    "\n",
    "# 2. Freeze the weights of the base model\n",
    "# This prevents the pre-trained weights from being updated during training.\n",
    "base_model.trainable = False\n",
    "\n",
    "# 3. Build your new custom classification head\n",
    "inputs = tf.keras.Input(shape=(240, 240, 3))\n",
    "x = base_model(inputs, training=False) # Pass the inputs through the frozen base\n",
    "x = layers.GlobalAveragePooling2D()(x) # Apply pooling\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "class_output = Dense(n_classes, activation=\"softmax\", name='class_id')(x)\n",
    "\n",
    "cid_model = Model(inputs=inputs, outputs=class_output, name='cid_model')\n",
    "\n",
    "cid_model.compile(\n",
    "    optimizer= tf.keras.optimizers.Adam(),\n",
    "    loss=losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b06785c-7355-416b-bac5-048a7b1d8642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = cid_model.fit(cid_train_ds, validation_data=cid_val_ds, epochs=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2cfbd6-035a-4388-8154-1781ab8e6961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 239ms/step - accuracy: 0.5242 - loss: 0.2181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21807317435741425, 0.5241641402244568]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ven_model.evaluate(ven_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa768ba-ed9b-4888-afbf-3434be1881f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m143/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25s\u001b[0m 642ms/step - accuracy: 0.4326 - loss: 11136.6466"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 12:34:23.141665: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 726ms/step - accuracy: 0.7550 - loss: 454028.0000 - val_accuracy: 0.8956 - val_loss: 3079024.2500\n",
      "Epoch 2/3\n",
      "\u001b[1m143/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m25s\u001b[0m 652ms/step - accuracy: 0.8916 - loss: 17912041.7517"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 12:36:36.856742: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 730ms/step - accuracy: 0.8940 - loss: 86519640.0000 - val_accuracy: 0.8956 - val_loss: 313882272.0000\n",
      "Epoch 3/3\n",
      "\u001b[1m143/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m26s\u001b[0m 675ms/step - accuracy: 0.8916 - loss: 562706241.6783"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 12:38:53.134662: W tensorflow/core/lib/png/png_io.cc:95] PNG warning: iCCP: extra compressed data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 754ms/step - accuracy: 0.8940 - loss: 1166290688.0000 - val_accuracy: 0.8956 - val_loss: 2586675456.0000\n",
      "CPU times: user 46min 26s, sys: 13.5 s, total: 46min 40s\n",
      "Wall time: 6min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = cid_model.fit(cid_train_ds, validation_data=cid_val_ds, epochs=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d82a1-e667-499b-b679-aba6c9273393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 242ms/step - accuracy: 0.8980 - loss: 767027456.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[767027456.0, 0.898024320602417]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cid_model.evaluate(cid_test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
